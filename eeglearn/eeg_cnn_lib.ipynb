{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (utils.py, line 127)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Users\\zx305\\.conda\\envs\\EEG-Python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m2961\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-a465822fd10a>\"\u001b[1;36m, line \u001b[1;32m15\u001b[1;36m, in \u001b[1;35m<module>\u001b[1;36m\u001b[0m\n\u001b[1;33m    from utils import augment_EEG, cart2sph, pol2cart\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"E:\\360MoveData\\Users\\zx305\\Documents\\GitHub\\EEGLearn\\eeglearn\\utils.py\"\u001b[1;36m, line \u001b[1;32m127\u001b[0m\n\u001b[1;33m    print 'Original: {0}'.format(data)\u001b[0m\n\u001b[1;37m                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1234)\n",
    "from functools import reduce\n",
    "import math as m\n",
    "\n",
    "import scipy.io\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "from scipy.interpolate import griddata\n",
    "from sklearn.preprocessing import scale\n",
    "from utils import augment_EEG, cart2sph, pol2cart\n",
    "\n",
    "import lasagne\n",
    "from lasagne.regularization import regularize_layer_params,regularize_network_params, l1, l2\n",
    "from lasagne.layers import Conv2DLayer, MaxPool2DLayer, InputLayer\n",
    "from lasagne.layers import DenseLayer, ElemwiseMergeLayer, FlattenLayer\n",
    "from lasagne.layers import ConcatLayer, ReshapeLayer, get_output_shape\n",
    "from lasagne.layers import Conv1DLayer, DimshuffleLayer, LSTMLayer, SliceLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def azim_proj(pos):\n",
    "    \"\"\"\n",
    "    Computes the Azimuthal Equidistant Projection of input point in 3D Cartesian Coordinates.\n",
    "    Imagine a plane being placed against (tangent to) a globe. If\n",
    "    a light source inside the globe projects the graticule onto\n",
    "    the plane the result would be a planar, or azimuthal, map\n",
    "    projection.\n",
    "\n",
    "    :param pos: position in 3D Cartesian coordinates\n",
    "    :return: projected coordinates using Azimuthal Equidistant Projection\n",
    "    \"\"\"\n",
    "    [r, elev, az] = cart2sph(pos[0], pos[1], pos[2])\n",
    "    return pol2cart(az, m.pi / 2 - elev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_images(locs, features, n_gridpoints, normalize=True,\n",
    "               augment=False, pca=False, std_mult=0.1, n_components=2, edgeless=False):\n",
    "    \"\"\"\n",
    "    Generates EEG images given electrode locations in 2D space and multiple feature values for each electrode\n",
    "\n",
    "    :param locs: An array with shape [n_electrodes, 2] containing X, Y\n",
    "                        coordinates for each electrode.\n",
    "    :param features: Feature matrix as [n_samples, n_features]\n",
    "                                Features are as columns.\n",
    "                                Features corresponding to each frequency band are concatenated.\n",
    "                                (alpha1, alpha2, ..., beta1, beta2,...)\n",
    "    :param n_gridpoints: Number of pixels in the output images\n",
    "    :param normalize:   Flag for whether to normalize each band over all samples\n",
    "    :param augment:     Flag for generating augmented images\n",
    "    :param pca:         Flag for PCA based data augmentation\n",
    "    :param std_mult     Multiplier for std of added noise\n",
    "    :param n_components: Number of components in PCA to retain for augmentation\n",
    "    :param edgeless:    If True generates edgeless images by adding artificial channels\n",
    "                        at four corners of the image with value = 0 (default=False).\n",
    "    :return:            Tensor of size [samples, colors, W, H] containing generated\n",
    "                        images.\n",
    "    \"\"\"\n",
    "    feat_array_temp = []\n",
    "    nElectrodes = locs.shape[0]     # Number of electrodes\n",
    "\n",
    "    # Test whether the feature vector length is divisible by number of electrodes\n",
    "    assert features.shape[1] % nElectrodes == 0\n",
    "    n_colors = features.shape[1] / nElectrodes\n",
    "    for c in range(n_colors):\n",
    "        feat_array_temp.append(features[:, c * nElectrodes : nElectrodes * (c+1)])\n",
    "    if augment:\n",
    "        if pca:\n",
    "            for c in range(n_colors):\n",
    "                feat_array_temp[c] = augment_EEG(feat_array_temp[c], std_mult, pca=True, n_components=n_components)\n",
    "        else:\n",
    "            for c in range(n_colors):\n",
    "                feat_array_temp[c] = augment_EEG(feat_array_temp[c], std_mult, pca=False, n_components=n_components)\n",
    "    n_samples = features.shape[0]\n",
    "\n",
    "    # Interpolate the values\n",
    "    grid_x, grid_y = np.mgrid[\n",
    "                     min(locs[:, 0]):max(locs[:, 0]):n_gridpoints*1j,\n",
    "                     min(locs[:, 1]):max(locs[:, 1]):n_gridpoints*1j\n",
    "                     ]\n",
    "    temp_interp = []\n",
    "    for c in range(n_colors):\n",
    "        temp_interp.append(np.zeros([n_samples, n_gridpoints, n_gridpoints]))\n",
    "\n",
    "    # Generate edgeless images\n",
    "    if edgeless:\n",
    "        min_x, min_y = np.min(locs, axis=0)\n",
    "        max_x, max_y = np.max(locs, axis=0)\n",
    "        locs = np.append(locs, np.array([[min_x, min_y], [min_x, max_y], [max_x, min_y], [max_x, max_y]]), axis=0)\n",
    "        for c in range(n_colors):\n",
    "            feat_array_temp[c] = np.append(feat_array_temp[c], np.zeros((n_samples, 4)), axis=1)\n",
    "\n",
    "    # Interpolating\n",
    "    for i in xrange(n_samples):\n",
    "        for c in range(n_colors):\n",
    "            temp_interp[c][i, :, :] = griddata(locs, feat_array_temp[c][i, :], (grid_x, grid_y),\n",
    "                                               method='cubic', fill_value=np.nan)\n",
    "        print('Interpolating {0}/{1}\\r'.format(i + 1, n_samples), end='\\r')\n",
    "\n",
    "    # Normalizing\n",
    "    for c in range(n_colors):\n",
    "        if normalize:\n",
    "            temp_interp[c][~np.isnan(temp_interp[c])] = \\\n",
    "                scale(temp_interp[c][~np.isnan(temp_interp[c])])\n",
    "        temp_interp[c] = np.nan_to_num(temp_interp[c])\n",
    "    return np.swapaxes(np.asarray(temp_interp), 0, 1)     # swap axes to have [samples, colors, W, H]\n",
    "\n",
    "\n",
    "def build_cnn(input_var=None, w_init=None, n_layers=(4, 2, 1), n_filters_first=32, imsize=32, n_colors=3):\n",
    "    \"\"\"\n",
    "    Builds a VGG style CNN network followed by a fully-connected layer and a softmax layer.\n",
    "    Stacks are separated by a maxpool layer. Number of kernels in each layer is twice\n",
    "    the number in previous stack.\n",
    "    input_var: Theano variable for input to the network\n",
    "    outputs: pointer to the output of the last layer of network (softmax)\n",
    "\n",
    "    :param input_var: theano variable as input to the network\n",
    "    :param w_init: Initial weight values\n",
    "    :param n_layers: number of layers in each stack. An array of integers with each\n",
    "                    value corresponding to the number of layers in each stack.\n",
    "                    (e.g. [4, 2, 1] == 3 stacks with 4, 2, and 1 layers in each.\n",
    "    :param n_filters_first: number of filters in the first layer\n",
    "    :param imsize: Size of the image\n",
    "    :param n_colors: Number of color channels (depth)\n",
    "    :return: a pointer to the output of last layer\n",
    "    \"\"\"\n",
    "    weights = []        # Keeps the weights for all layers\n",
    "    count = 0\n",
    "    # If no initial weight is given, initialize with GlorotUniform\n",
    "    if w_init is None:\n",
    "        w_init = [lasagne.init.GlorotUniform()] * sum(n_layers)\n",
    "    # Input layer\n",
    "    network = InputLayer(shape=(None, n_colors, imsize, imsize),\n",
    "                                        input_var=input_var)\n",
    "    for i, s in enumerate(n_layers):\n",
    "        for l in range(s):\n",
    "            network = Conv2DLayer(network, num_filters=n_filters_first * (2 ** i), filter_size=(3, 3),\n",
    "                          W=w_init[count], pad='same')\n",
    "            count += 1\n",
    "            weights.append(network.W)\n",
    "        network = MaxPool2DLayer(network, pool_size=(2, 2))\n",
    "    return network, weights\n",
    "\n",
    "\n",
    "def build_convpool_max(input_vars, nb_classes, imsize=32, n_colors=3, n_timewin=7):\n",
    "    \"\"\"\n",
    "    Builds the complete network with maxpooling layer in time.\n",
    "\n",
    "    :param input_vars: list of EEG images (one image per time window)\n",
    "    :param nb_classes: number of classes\n",
    "    :param imsize: size of the input image (assumes a square input)\n",
    "    :param n_colors: number of color channels in the image\n",
    "    :param n_timewin: number of time windows in the snippet\n",
    "    :return: a pointer to the output of last layer\n",
    "    \"\"\"\n",
    "    convnets = []\n",
    "    w_init = None\n",
    "    # Build 7 parallel CNNs with shared weights\n",
    "    for i in range(n_timewin):\n",
    "        if i == 0:\n",
    "            convnet, w_init = build_cnn(input_vars[i], imsize=imsize, n_colors=n_colors)\n",
    "        else:\n",
    "            convnet, _ = build_cnn(input_vars[i], w_init=w_init, imsize=imsize, n_colors=n_colors)\n",
    "        convnets.append(convnet)\n",
    "    # convpooling using Max pooling over frames\n",
    "    convpool = ElemwiseMergeLayer(convnets, theano.tensor.maximum)\n",
    "    # A fully-connected layer of 512 units with 50% dropout on its inputs:\n",
    "    convpool = DenseLayer(lasagne.layers.dropout(convpool, p=.5),\n",
    "            num_units=512, nonlinearity=lasagne.nonlinearities.rectify)\n",
    "    # And, finally, the output layer with 50% dropout on its inputs:\n",
    "    convpool = lasagne.layers.DenseLayer(lasagne.layers.dropout(convpool, p=.5),\n",
    "            num_units=nb_classes, nonlinearity=lasagne.nonlinearities.softmax)\n",
    "    return convpool\n",
    "\n",
    "\n",
    "def build_convpool_conv1d(input_vars, nb_classes, imsize=32, n_colors=3, n_timewin=7):\n",
    "    \"\"\"\n",
    "    Builds the complete network with 1D-conv layer to integrate time from sequences of EEG images.\n",
    "\n",
    "    :param input_vars: list of EEG images (one image per time window)\n",
    "    :param nb_classes: number of classes\n",
    "    :param imsize: size of the input image (assumes a square input)\n",
    "    :param n_colors: number of color channels in the image\n",
    "    :param n_timewin: number of time windows in the snippet\n",
    "    :return: a pointer to the output of last layer\n",
    "    \"\"\"\n",
    "    convnets = []\n",
    "    w_init = None\n",
    "    # Build 7 parallel CNNs with shared weights\n",
    "    for i in range(n_timewin):\n",
    "        if i == 0:\n",
    "            convnet, w_init = build_cnn(input_vars[i], imsize=imsize, n_colors=n_colors)\n",
    "        else:\n",
    "            convnet, _ = build_cnn(input_vars[i], w_init=w_init, imsize=imsize, n_colors=n_colors)\n",
    "        convnets.append(FlattenLayer(convnet))\n",
    "    # at this point convnets shape is [numTimeWin][n_samples, features]\n",
    "    # we want the shape to be [n_samples, features, numTimeWin]\n",
    "    convpool = ConcatLayer(convnets)\n",
    "    convpool = ReshapeLayer(convpool, ([0], n_timewin, get_output_shape(convnets[0])[1]))\n",
    "    convpool = DimshuffleLayer(convpool, (0, 2, 1))\n",
    "    # input to 1D convlayer should be in (batch_size, num_input_channels, input_length)\n",
    "    convpool = Conv1DLayer(convpool, 64, 3)\n",
    "    # A fully-connected layer of 512 units with 50% dropout on its inputs:\n",
    "    convpool = DenseLayer(lasagne.layers.dropout(convpool, p=.5),\n",
    "            num_units=512, nonlinearity=lasagne.nonlinearities.rectify)\n",
    "    # And, finally, the output layer with 50% dropout on its inputs:\n",
    "    convpool = DenseLayer(lasagne.layers.dropout(convpool, p=.5),\n",
    "            num_units=nb_classes, nonlinearity=lasagne.nonlinearities.softmax)\n",
    "    return convpool\n",
    "\n",
    "\n",
    "def build_convpool_lstm(input_vars, nb_classes, grad_clip=110, imsize=32, n_colors=3, n_timewin=7):\n",
    "    \"\"\"\n",
    "    Builds the complete network with LSTM layer to integrate time from sequences of EEG images.\n",
    "\n",
    "    :param input_vars: list of EEG images (one image per time window)\n",
    "    :param nb_classes: number of classes\n",
    "    :param grad_clip:  the gradient messages are clipped to the given value during\n",
    "                        the backward pass.\n",
    "    :param imsize: size of the input image (assumes a square input)\n",
    "    :param n_colors: number of color channels in the image\n",
    "    :param n_timewin: number of time windows in the snippet\n",
    "    :return: a pointer to the output of last layer\n",
    "    \"\"\"\n",
    "    convnets = []\n",
    "    w_init = None\n",
    "    # Build 7 parallel CNNs with shared weights\n",
    "    for i in range(n_timewin):\n",
    "        if i == 0:\n",
    "            convnet, w_init = build_cnn(input_vars[i], imsize=imsize, n_colors=n_colors)\n",
    "        else:\n",
    "            convnet, _ = build_cnn(input_vars[i], w_init=w_init, imsize=imsize, n_colors=n_colors)\n",
    "        convnets.append(FlattenLayer(convnet))\n",
    "    # at this point convnets shape is [numTimeWin][n_samples, features]\n",
    "    # we want the shape to be [n_samples, features, numTimeWin]\n",
    "    convpool = ConcatLayer(convnets)\n",
    "    convpool = ReshapeLayer(convpool, ([0], n_timewin, get_output_shape(convnets[0])[1]))\n",
    "    # Input to LSTM should have the shape as (batch size, SEQ_LENGTH, num_features)\n",
    "    convpool = LSTMLayer(convpool, num_units=128, grad_clipping=grad_clip,\n",
    "        nonlinearity=lasagne.nonlinearities.tanh)\n",
    "    # We only need the final prediction, we isolate that quantity and feed it\n",
    "    # to the next layer.\n",
    "    convpool = SliceLayer(convpool, -1, 1)      # Selecting the last prediction\n",
    "    # A fully-connected layer of 256 units with 50% dropout on its inputs:\n",
    "    convpool = DenseLayer(lasagne.layers.dropout(convpool, p=.5),\n",
    "            num_units=256, nonlinearity=lasagne.nonlinearities.rectify)\n",
    "    # And, finally, the output layer with 50% dropout on its inputs:\n",
    "    convpool = DenseLayer(lasagne.layers.dropout(convpool, p=.5),\n",
    "            num_units=nb_classes, nonlinearity=lasagne.nonlinearities.softmax)\n",
    "    return convpool\n",
    "\n",
    "\n",
    "def build_convpool_mix(input_vars, nb_classes, grad_clip=110, imsize=32, n_colors=3, n_timewin=7):\n",
    "    \"\"\"\n",
    "    Builds the complete network with LSTM and 1D-conv layers combined\n",
    "\n",
    "    :param input_vars: list of EEG images (one image per time window)\n",
    "    :param nb_classes: number of classes\n",
    "    :param grad_clip:  the gradient messages are clipped to the given value during\n",
    "                        the backward pass.\n",
    "    :param imsize: size of the input image (assumes a square input)\n",
    "    :param n_colors: number of color channels in the image\n",
    "    :param n_timewin: number of time windows in the snippet\n",
    "    :return: a pointer to the output of last layer\n",
    "    \"\"\"\n",
    "    convnets = []\n",
    "    w_init = None\n",
    "    # Build 7 parallel CNNs with shared weights\n",
    "    for i in range(n_timewin):\n",
    "        if i == 0:\n",
    "            convnet, w_init = build_cnn(input_vars[i], imsize=imsize, n_colors=n_colors)\n",
    "        else:\n",
    "            convnet, _ = build_cnn(input_vars[i], w_init=w_init, imsize=imsize, n_colors=n_colors)\n",
    "        convnets.append(FlattenLayer(convnet))\n",
    "    # at this point convnets shape is [numTimeWin][n_samples, features]\n",
    "    # we want the shape to be [n_samples, features, numTimeWin]\n",
    "    convpool = ConcatLayer(convnets)\n",
    "    convpool = ReshapeLayer(convpool, ([0], n_timewin, get_output_shape(convnets[0])[1]))\n",
    "    reformConvpool = DimshuffleLayer(convpool, (0, 2, 1))\n",
    "    # input to 1D convlayer should be in (batch_size, num_input_channels, input_length)\n",
    "    conv_out = Conv1DLayer(reformConvpool, 64, 3)\n",
    "    conv_out = FlattenLayer(conv_out)\n",
    "    # Input to LSTM should have the shape as (batch size, SEQ_LENGTH, num_features)\n",
    "    lstm = LSTMLayer(convpool, num_units=128, grad_clipping=grad_clip,\n",
    "        nonlinearity=lasagne.nonlinearities.tanh)\n",
    "    lstm_out = SliceLayer(lstm, -1, 1)\n",
    "    # Merge 1D-Conv and LSTM outputs\n",
    "    dense_input = ConcatLayer([conv_out, lstm_out])\n",
    "    # A fully-connected layer of 256 units with 50% dropout on its inputs:\n",
    "    convpool = DenseLayer(lasagne.layers.dropout(dense_input, p=.5),\n",
    "            num_units=512, nonlinearity=lasagne.nonlinearities.rectify)\n",
    "    # And, finally, the 10-unit output layer with 50% dropout on its inputs:\n",
    "    convpool = DenseLayer(convpool,\n",
    "            num_units=nb_classes, nonlinearity=lasagne.nonlinearities.softmax)\n",
    "    return convpool\n",
    "\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    \"\"\"\n",
    "    Iterates over the samples returing batches of size batchsize.\n",
    "    :param inputs: input data array. It should be a 4D numpy array for images [n_samples, n_colors, W, H] and 5D numpy\n",
    "                    array if working with sequence of images [n_timewindows, n_samples, n_colors, W, H].\n",
    "    :param targets: vector of target labels.\n",
    "    :param batchsize: Batch size\n",
    "    :param shuffle: Flag whether to shuffle the samples before iterating or not.\n",
    "    :return: images and labels for a batch\n",
    "    \"\"\"\n",
    "    if inputs.ndim == 4:\n",
    "        input_len = inputs.shape[0]\n",
    "    elif inputs.ndim == 5:\n",
    "        input_len = inputs.shape[1]\n",
    "    assert input_len == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(input_len)\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, input_len, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        if inputs.ndim == 4:\n",
    "            yield inputs[excerpt], targets[excerpt]\n",
    "        elif inputs.ndim == 5:\n",
    "            yield inputs[:, excerpt], targets[excerpt]\n",
    "\n",
    "\n",
    "def train(images, labels, fold, model_type, batch_size=32, num_epochs=5):\n",
    "    \"\"\"\n",
    "    A sample training function which loops over the training set and evaluates the network\n",
    "    on the validation set after each epoch. Evaluates the network on the training set\n",
    "    whenever the\n",
    "    :param images: input images\n",
    "    :param labels: target labels\n",
    "    :param fold: tuple of (train, test) index numbers\n",
    "    :param model_type: model type ('cnn', '1dconv', 'maxpool', 'lstm', 'mix')\n",
    "    :param batch_size: batch size for training\n",
    "    :param num_epochs: number of epochs of dataset to go over for training\n",
    "    :return: none\n",
    "    \"\"\"\n",
    "    num_classes = len(np.unique(labels))\n",
    "    (X_train, y_train), (X_val, y_val), (X_test, y_test) = reformatInput(images, labels, fold)\n",
    "    X_train = X_train.astype(\"float32\", casting='unsafe')\n",
    "    X_val = X_val.astype(\"float32\", casting='unsafe')\n",
    "    X_test = X_test.astype(\"float32\", casting='unsafe')\n",
    "    # Prepare Theano variables for inputs and targets\n",
    "    input_var = T.TensorType('floatX', ((False,) * 5))()\n",
    "    target_var = T.ivector('targets')\n",
    "    # Create neural network model (depending on first command line parameter)\n",
    "    print(\"Building model and compiling functions...\")\n",
    "    # Building the appropriate model\n",
    "    if model_type == '1dconv':\n",
    "        network = build_convpool_conv1d(input_var, num_classes)\n",
    "    elif model_type == 'maxpool':\n",
    "        network = build_convpool_max(input_var, num_classes)\n",
    "    elif model_type == 'lstm':\n",
    "        network = build_convpool_lstm(input_var, num_classes, 100)\n",
    "    elif model_type == 'mix':\n",
    "        network = build_convpool_mix(input_var, num_classes, 100)\n",
    "    elif model_type == 'cnn':\n",
    "        input_var = T.tensor4('inputs')\n",
    "        network, _ = build_cnn(input_var)\n",
    "        network = DenseLayer(lasagne.layers.dropout(network, p=.5),\n",
    "                             num_units=256,\n",
    "                             nonlinearity=lasagne.nonlinearities.rectify)\n",
    "        network = DenseLayer(lasagne.layers.dropout(network, p=.5),\n",
    "                             num_units=num_classes,\n",
    "                             nonlinearity=lasagne.nonlinearities.softmax)\n",
    "    else:\n",
    "        raise ValueError(\"Model not supported ['1dconv', 'maxpool', 'lstm', 'mix', 'cnn']\")\n",
    "    # Create a loss expression for training, i.e., a scalar objective we want\n",
    "    # to minimize (for our multi-class problem, it is the cross-entropy loss):\n",
    "    prediction = lasagne.layers.get_output(network)\n",
    "    loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "    loss = loss.mean()\n",
    "    reg_factor = 1e-4\n",
    "    l2_penalty = regularize_network_params(network, l2) * reg_factor\n",
    "    loss += l2_penalty\n",
    "\n",
    "    params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "    updates = lasagne.updates.adam(loss, params, learning_rate=0.001)\n",
    "    # Create a loss expression for validation/testing. The crucial difference\n",
    "    # here is that we do a deterministic forward pass through the network,\n",
    "    # disabling dropout layers.\n",
    "    test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "    test_loss = lasagne.objectives.categorical_crossentropy(test_prediction,\n",
    "                                                            target_var)\n",
    "    test_loss = test_loss.mean()\n",
    "    # As a bonus, also create an expression for the classification accuracy:\n",
    "    test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var),\n",
    "                      dtype=theano.config.floatX)\n",
    "    # Compile a function performing a training step on a mini-batch (by giving\n",
    "    # the updates dictionary) and returning the corresponding training loss:\n",
    "    train_fn = theano.function([input_var, target_var], loss, updates=updates)\n",
    "    # Compile a second function computing the validation loss and accuracy:\n",
    "    val_fn = theano.function([input_var, target_var], [test_loss, test_acc])\n",
    "    # Finally, launch the training loop.\n",
    "    print(\"Starting training...\")\n",
    "    best_validation_accu = 0\n",
    "    # We iterate over epochs:\n",
    "    for epoch in range(num_epochs):\n",
    "        # In each epoch, we do a full pass over the training data:\n",
    "        train_err = 0\n",
    "        train_batches = 0\n",
    "        start_time = time.time()\n",
    "        for batch in iterate_minibatches(X_train, y_train, batch_size, shuffle=False):\n",
    "            inputs, targets = batch\n",
    "            train_err += train_fn(inputs, targets)\n",
    "            train_batches += 1\n",
    "        # And a full pass over the validation data:\n",
    "        val_err = 0\n",
    "        val_acc = 0\n",
    "        val_batches = 0\n",
    "        for batch in iterate_minibatches(X_val, y_val, batch_size, shuffle=False):\n",
    "            inputs, targets = batch\n",
    "            err, acc = val_fn(inputs, targets)\n",
    "            val_err += err\n",
    "            val_acc += acc\n",
    "            val_batches += 1\n",
    "        av_train_err = train_err / train_batches\n",
    "        av_val_err = val_err / val_batches\n",
    "        av_val_acc = val_acc / val_batches\n",
    "        # Then we print the results for this epoch:\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "            epoch + 1, num_epochs, time.time() - start_time))\n",
    "        print(\"  training loss:\\t\\t{:.6f}\".format(av_train_err))\n",
    "        print(\"  validation loss:\\t\\t{:.6f}\".format(av_val_err))\n",
    "        print(\"  validation accuracy:\\t\\t{:.2f} %\".format(av_val_acc * 100))\n",
    "        if av_val_acc > best_validation_accu:\n",
    "            best_validation_accu = av_val_acc\n",
    "            # After training, we compute and print the test error:\n",
    "            test_err = 0\n",
    "            test_acc = 0\n",
    "            test_batches = 0\n",
    "            for batch in iterate_minibatches(X_test, y_test, batch_size, shuffle=False):\n",
    "                inputs, targets = batch\n",
    "                err, acc = val_fn(inputs, targets)\n",
    "                test_err += err\n",
    "                test_acc += acc\n",
    "                test_batches += 1\n",
    "            av_test_err = test_err / test_batches\n",
    "            av_test_acc = test_acc / test_batches\n",
    "            print(\"Final results:\")\n",
    "            print(\"  test loss:\\t\\t\\t{:.6f}\".format(av_test_err))\n",
    "            print(\"  test accuracy:\\t\\t{:.2f} %\".format(av_test_acc * 100))\n",
    "            # Dump the network weights to a file like this:\n",
    "            np.savez('weights_lasg_{0}'.format(model_type), *lasagne.layers.get_all_param_values(network))\n",
    "    print('-'*50)\n",
    "    print(\"Best validation accuracy:\\t\\t{:.2f} %\".format(best_validation_accu * 100))\n",
    "    print(\"Best test accuracy:\\t\\t{:.2f} %\".format(av_test_acc * 100))\n",
    "    return av_test_acc\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from utils import reformatInput\n",
    "\n",
    "    # Load electrode locations\n",
    "    print('Loading data...')\n",
    "    locs = scipy.io.loadmat('../Sample data/Neuroscan_locs_orig.mat')\n",
    "    locs_3d = locs['A']\n",
    "    locs_2d = []\n",
    "    # Convert to 2D\n",
    "    for e in locs_3d:\n",
    "        locs_2d.append(azim_proj(e))\n",
    "\n",
    "    feats = scipy.io.loadmat('../Sample data/FeatureMat_timeWin.mat')['features']\n",
    "    subj_nums = np.squeeze(scipy.io.loadmat('../Sample data/trials_subNums.mat')['subjectNum'])\n",
    "    # Leave-Subject-Out cross validation\n",
    "    fold_pairs = []\n",
    "    for i in np.unique(subj_nums):\n",
    "        ts = subj_nums == i\n",
    "        tr = np.squeeze(np.nonzero(np.bitwise_not(ts)))\n",
    "        ts = np.squeeze(np.nonzero(ts))\n",
    "        np.random.shuffle(tr)  # Shuffle indices\n",
    "        np.random.shuffle(ts)\n",
    "        fold_pairs.append((tr, ts))\n",
    "\n",
    "    # CNN Mode\n",
    "    print('Generating images...')\n",
    "    # Find the average response over time windows\n",
    "    av_feats = reduce(lambda x, y: x+y, [feats[:, i*192:(i+1)*192] for i in range(feats.shape[1] / 192)])\n",
    "    av_feats = av_feats / (feats.shape[1] / 192)\n",
    "    images = gen_images(np.array(locs_2d),\n",
    "                        av_feats,\n",
    "                        32, normalize=True)\n",
    "    print('\\n')\n",
    "\n",
    "    # Class labels should start from 0\n",
    "    print('Training the CNN Model...')\n",
    "    test_acc_cnn = []\n",
    "    for i in range(len(fold_pairs)):\n",
    "        print('fold {0}/{1}'.format(i + 1, len(fold_pairs)))\n",
    "        test_acc_cnn.append(train(images, np.squeeze(feats[:, -1]) - 1, fold_pairs[i], 'cnn', num_epochs=10))\n",
    "\n",
    "    # Conv-LSTM Mode\n",
    "    print('Generating images for all time windows...')\n",
    "    images_timewin = np.array([gen_images(np.array(locs_2d),\n",
    "                                          feats[:, i * 192:(i + 1) * 192], 32, normalize=True) for i in\n",
    "                               range(feats.shape[1] / 192)\n",
    "                               ])\n",
    "    print('\\n')\n",
    "    print('Training the LSTM-CONV Model...')\n",
    "    test_acc_mix = []\n",
    "    for i in range(len(fold_pairs)):\n",
    "        print('fold {0}/{1}'.format(i+1, len(fold_pairs)))\n",
    "        test_acc_mix.append(train(images_timewin, np.squeeze(feats[:, -1]) - 1, fold_pairs[i], 'mix', num_epochs=10))\n",
    "    print('*' * 40)\n",
    "    print('Average MIX test accuracy: {0}'.format(np.mean(test_acc_mix)*100))\n",
    "    print('Average CNN test accuracy: {0}'.format(np.mean(test_acc_cnn) * 100))\n",
    "    print('*' * 40)\n",
    "\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
